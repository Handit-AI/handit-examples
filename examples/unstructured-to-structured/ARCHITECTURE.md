# System Architecture

This document explains the technical architecture of the Unstructured to Structured Data Converter.

## ğŸ—ï¸ High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   FastAPI       â”‚    â”‚   LangGraph      â”‚    â”‚   OpenAI        â”‚
â”‚   Server        â”‚    â”‚   Workflow       â”‚    â”‚   LLM Models    â”‚
â”‚                 â”‚    â”‚                  â”‚    â”‚                 â”‚
â”‚ â€¢ File Upload   â”‚â”€â”€â”€â–¶â”‚ â€¢ Schema         â”‚â”€â”€â”€â–¶â”‚ â€¢ GPT-4o-mini   â”‚
â”‚ â€¢ Session Mgmt  â”‚    â”‚   Inference      â”‚    â”‚ â€¢ Vision        â”‚
â”‚ â€¢ API Endpoints â”‚    â”‚ â€¢ Data Capture   â”‚    â”‚ â€¢ Text          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ â€¢ CSV Generation â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”„ Workflow Flow

### 1. Document Upload (FastAPI)
- **Endpoint**: `POST /bulk-unstructured-to-structured`
- **Input**: Multiple files + session_id
- **Output**: Files saved to session directory
- **Next**: Triggers LangGraph workflow

### 2. Schema Inference (Node 1)
- **Input**: All uploaded documents (images, PDFs, text)
- **Process**: Multimodal LLM analysis
- **Output**: Unified JSON schema
- **Key**: Works with any document type

### 3. Data Extraction (Node 2)
- **Input**: Documents + inferred schema
- **Process**: Field mapping with confidence scoring
- **Output**: Structured JSON files
- **Key**: Strict schema adherence

### 4. CSV Generation (Node 3)
- **Input**: Structured JSON files
- **Process**: LLM table planning + pandas
- **Output**: Organized CSV tables
- **Key**: Automatic table design

## ğŸ“Š Data Flow

```
Documents â†’ Schema â†’ Structured JSON â†’ CSV Tables
    â†“           â†“           â†“            â†“
  Upload    Inference   Extraction   Generation
```

## ğŸ§© Component Details

### FastAPI Server (`main.py`)
- **Purpose**: HTTP API interface
- **Features**: File upload, session management, CORS
- **Integration**: Calls LangGraph workflow

### LangGraph Workflow (`graph/graph.py`)
- **Purpose**: Orchestrates the 3-step process
- **State Management**: Passes data between nodes
- **Error Handling**: Graceful failure recovery

### Processing Nodes
Each node is a Python function that:
- Receives state from previous node
- Processes data using LLM chains
- Updates state for next node
- Handles errors gracefully

### LLM Chains (`graph/chains/`)
- **document_inference**: Schema creation
- **invoice_data_extraction**: Field mapping
- **generation**: CSV table planning

## ğŸ”§ State Management

The `GraphState` class manages data flow:

```python
class GraphState(TypedDict, total=False):
    session_id: str                    # Unique session identifier
    unstructured_paths: List[str]      # Input file paths
    inferred_schema: Dict[str, Any]   # Generated schema
    structured_json_paths: List[str]   # Output JSON files
    generated_csv_paths: List[str]     # Output CSV files
    errors: List[str]                  # Error tracking
    execution_id: str                  # Tracing ID
```

## ğŸš€ Performance Considerations

### Scalability
- **Session-based processing**: Each upload creates isolated session
- **File batching**: Process multiple documents together
- **Memory management**: Files processed sequentially

### Optimization Opportunities
- **Parallel processing**: Process documents concurrently
- **Caching**: Cache schemas for similar document types
- **Streaming**: Handle large files without loading into memory

## ğŸ”’ Security & Privacy

### File Handling
- Files saved to session-specific directories
- No cross-session data leakage
- Temporary storage (consider cleanup policies)

### API Security
- CORS configuration for web clients
- Session isolation
- Input validation and sanitization

## ğŸ§ª Testing Strategy

### Unit Testing
- Test individual nodes in isolation
- Mock LLM responses
- Validate state transitions

### Integration Testing
- End-to-end workflow testing
- Sample document processing
- Error scenario validation

### Performance Testing
- Large document set processing
- Memory usage monitoring
- Response time benchmarking

## ğŸ”® Future Enhancements

### Planned Features
- **Better PDF support**: Page-by-page image extraction
- **Schema validation**: Confidence scoring for schemas
- **Custom field mapping**: User-defined field rules
- **Batch processing**: Queue-based processing for large sets

### Technical Improvements
- **Async processing**: Non-blocking file processing
- **Database integration**: Persistent schema storage
- **API rate limiting**: Prevent abuse
- **Monitoring**: Metrics and alerting

## ğŸ“š Related Documentation

- [LangGraph Concepts](https://langchain-ai.github.io/langgraph/concepts/)
- [FastAPI Best Practices](https://fastapi.tiangolo.com/tutorial/best-practices/)
- [OpenAI API Reference](https://platform.openai.com/docs/api-reference)

---

This architecture provides a solid foundation for document processing while maintaining flexibility for future enhancements.
